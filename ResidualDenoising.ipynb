{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline : Image denoising\n",
    "Before diving into the code, lets recap what image denoise is.\n",
    "\n",
    "Mathematically, a noisy image $y$ can be thought as being a sum between the latent image $x$ and some noise $n$ (N.B this is an approximation )  :\n",
    "\\begin{equation}\n",
    "y = x + n \n",
    "\\end{equation}\n",
    "\n",
    "Ideally, we would want a network that learns how to extract the latent image, and one common formulation for the loss function in this setting is the MSE :\n",
    "\\begin{equation}\n",
    "L = || y - x ||^2\n",
    "\\end{equation}\n",
    "with $y$ being the input of the net ( the noisy image ) and $x$ being the ground truth ( the latent image). \n",
    "\n",
    "However, this specific formulation has a major issue, mainly related to the fact that learning such a task can lead to unstable training and vanishing gradient problems.\n",
    "\n",
    "### A smart approach : Learning the residual\n",
    "\n",
    "In order to solve the problems that a deep CNN inherently encounters when trying to solve the task described above, a residual approach has been found to lead better training and results. The idea is quite simple: instead of trying to making the net output directly the latent image ( a complex problem in general ) the network tries to learn the residual image i.e the difference between the noisy image and the latent image : \n",
    "\\begin{equation}\n",
    "R(y,w) = y - x \n",
    "\\end{equation}\n",
    "the image is then reconstructed from this residual representation.\n",
    "Ideally, we would want the network to perfectly learn the noise in the image ( $R(y,w) \\approx n$ ). It is immediate to derive a loss function from the above expression, since we would want the residual learned to be as close as $y-x$. Bringing each term on the left hand side, we can derive the loss function as a usual MSE:\n",
    "\n",
    "\\begin{equation}\n",
    "L(y,w) = \\frac{1}{2N}\\sum_i^N  || R(y_i,w) - (y_i - x_i) ||^2\n",
    "\\end{equation}\n",
    "with $w$ being the parameters of the network and $N$ being the samples in out training set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A CNN model for denoising\n",
    "\n",
    "The architecture of the network is the same as the one described in https://arxiv.org/pdf/1608.03981.pdf\n",
    "\n",
    "Refer to the paper to see the implementation details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import MSELoss\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "class DcNN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_channels : int, filter_size : int, kernel_size : int,  depth : int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        A quick recap on the parameters used by pytorch. \n",
    "\n",
    "        in_channels : the number of channels in the tensor.\n",
    "    \n",
    "        out_channels : this is the filter size of the convolution.\n",
    "\n",
    "        kernel_size : this matches with the definition of the kernel\n",
    "\n",
    "        Example :   input.shape =  (1, 3 , 256, 256)\n",
    "\n",
    "                    conv2d = nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 3)\n",
    "\n",
    "        pls note here that different kernel sizes affects the output shape. having it as 3 does not affect it when padding = 1\n",
    "\n",
    "                    output = conv2d(input)\n",
    "\n",
    "                    output.shape   ->   (1, 64, 256, 256)\n",
    "\n",
    "        In summary, if one leaves the kernel to 3, with padding = 1 for each layer and no stride , the onnly value changing is the channel value.\n",
    "        This means that first layer in this implementation is taking as input the number of channels, and spitting out a tensor with same shape \n",
    "        but with a number of channels equal to the filter size. The midlle layers are not altering the shape, and finally the final conv layer\n",
    "        is returning the initial input shape\n",
    "                \n",
    "        \"\"\"\n",
    "        self.lossFunction = MSELoss(reduction=\"mean\")\n",
    "\n",
    "        self.firstConv = nn.Sequential(\n",
    "                         nn.Conv2d(in_channels = n_channels, out_channels = filter_size, kernel_size = kernel_size, padding = 1),\n",
    "                         nn.ReLU()\n",
    "        )\n",
    "\n",
    "     \n",
    "\n",
    "        middleLayer = nn.Sequential(\n",
    "                nn.Conv2d(in_channels = filter_size, out_channels = filter_size, kernel_size = kernel_size, padding = 1),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.middleLayers = nn.Sequential(* [ middleLayer for _ in range(depth - 2) ])\n",
    "\n",
    "        self.finalConv = nn.Conv2d(in_channels = filter_size, out_channels = n_channels, kernel_size = kernel_size, padding = 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.firstConv(x)\n",
    "        x = self.middleLayers(x)\n",
    "        out = self.finalConv(x)\n",
    "        return out\n",
    "    \n",
    "    def loss(self, noisy_images : torch.Tensor, clean_images : torch.Tensor ) -> torch.float:\n",
    "        \"\"\"\n",
    "                shape sizes : (batch_size, n_channels, width, height)\n",
    "        \n",
    "        \"\"\"\n",
    "        # loss = (R - ( y - x ) )^2      \n",
    "        # R : residual       \n",
    "\n",
    "        approximated_residual = self.forward(noisy_images)  #left term\n",
    "\n",
    "        real_residual = noisy_images - clean_images #right term\n",
    "\n",
    "        return self.lossFunction(approximated_residual, real_residual) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the model\n",
    "model = DcNN(n_channels=3, filter_size=64, kernel_size=3, depth=20)\n",
    "dummyRealImage = torch.rand((1, 3, 128, 128))\n",
    "dummyInput = torch.rand((1, 3, 128, 128))\n",
    "out = model(dummyInput)\n",
    "dummyLoss = model.loss(dummyInput, dummyRealImage )\n",
    "# print(f\"The shape of the output is the same as the input! : input shape {dummyInput.shape}, output shape {out.shape}  \")\n",
    "# print(f\"The loss function works and the its value is {dummyLoss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Creating the training set : Gaussian noise\n",
    "Staryting from a dataset of images, noisy images are simply obtained by adding gaussian noise with ranging std and mean to the clean image. Refer to the implementation in the dataset.py file.\n",
    "\n",
    "The images are coming from the CBSD68 dataset. Downloaaded from https://github.com/clausmichele/CBSD68-dataset/tree/master\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import NoisyDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "BATCH_SIZE = 64\n",
    "PATCH_DIMENSION = 50\n",
    "EPOCHS = 10\n",
    "dataset = NoisyDataset(dirPath=\"./dataset/original\", stdRange=(0,55), batchSize=BATCH_SIZE, patchDimension=PATCH_DIMENSION)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=None, shuffle=True)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the training loop\n",
    "\n",
    "We follow the same training procedure followed by the paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed loss after a batch training is 0.18899677693843842\n",
      "Computed loss after a batch training is 0.12780314683914185\n",
      "Computed loss after a batch training is 0.12218622118234634\n",
      "Computed loss after a batch training is 0.12605994939804077\n",
      "Computed loss after a batch training is 0.10808400809764862\n",
      "Computed loss after a batch training is 0.09375394135713577\n",
      "Computed loss after a batch training is 0.08834610134363174\n",
      "Computed loss after a batch training is 0.09219938516616821\n",
      "Computed loss after a batch training is 0.06919863820075989\n",
      "Computed loss after a batch training is 0.0645141452550888\n",
      "Computed loss after a batch training is 0.07085143774747849\n",
      "Computed loss after a batch training is 0.07034683972597122\n",
      "Computed loss after a batch training is 0.05827487260103226\n",
      "Computed loss after a batch training is 0.03920825198292732\n",
      "Computed loss after a batch training is 0.05426187440752983\n",
      "Computed loss after a batch training is 0.03288250416517258\n",
      "Computed loss after a batch training is 0.04039017856121063\n",
      "Computed loss after a batch training is 0.025829222053289413\n",
      "Computed loss after a batch training is 0.033706363290548325\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \n\u001b[1;32m      8\u001b[0m computedLoss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mloss(noisy_images\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m, clean_images\u001b[38;5;241m=\u001b[39mgroundT)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mcomputedLoss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     12\u001b[0m totalLoss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m computedLoss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/vscode/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vscode/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    model.train()\n",
    "    totalLoss = 0 \n",
    "    for input, groundT in dataloader:\n",
    "\n",
    "        optimizer.zero_grad()  \n",
    "        computedLoss = model.loss(noisy_images=input, clean_images=groundT)\n",
    "        computedLoss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        totalLoss += computedLoss.item()\n",
    "        print(f\"Computed loss after a batch training is {computedLoss}\")\n",
    "\n",
    "\n",
    "    print(f\"Model trained for {epoch} epoch, total loss is {totalLoss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VScode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
